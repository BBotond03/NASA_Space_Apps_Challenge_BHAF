{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BBotond03/NASA_Space_Apps_Challenge_BHAF/blob/main/deepl_bp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imprting data and initial data procession"
      ],
      "metadata": {
        "id": "Y_NOzcAGwqqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDZwRbat-pcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0673099a-6218-40ae-8a9a-5323e03be024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "# Install kaggle library\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "import cv2"
      ],
      "metadata": {
        "id": "3EQu68QVPJOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the user to upload their kaggle.json file to download the data\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded kaggle.json file to the proper directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_DVRMj3eTzMG",
        "outputId": "4ffd402d-0057-4a58-9267-77664797ccc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1419839e-165b-4ea2-b15b-f60dfa067798\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1419839e-165b-4ea2-b15b-f60dfa067798\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the training data from kaggle\n",
        "!kaggle competitions download -c airbus-ship-detection\n",
        "\n",
        "# Unzip the file and delete the zip afterwards in order to save spaece\n",
        "zip_file = '/content/airbus-ship-detection.zip'\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "os.remove(zip_file)\n",
        "if os.path.exists('/content/sample_data'):\n",
        "  shutil.rmtree('/content/sample_data')\n",
        "\n",
        "print(\"Download and extraction complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-jDoiUKUdzk",
        "outputId": "18b3b8e9-933f-455b-93bc-c4ab87dad3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading airbus-ship-detection.zip to /content\n",
            " 67% 19.1G/28.6G [15:50<08:02, 21.2MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data procession"
      ],
      "metadata": {
        "id": "TXT_bH2V4P0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First we just analyse the distribution of the pictures based on the number of ships. The reason for this is that we will find unnecesarly large amount of pics with 0 ships. Later on we will filter the data based on this to make the traning process faster and simpler. (Traning section)"
      ],
      "metadata": {
        "id": "vH6SJREyxEZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path to the .csv file containig the output rle-s\n",
        "csv_path = '/content/train_ship_segmentations_v2.csv'\n",
        "\n",
        "# Functio to count how many ships does each picture contains\n",
        "def count_ships(csv_path):\n",
        "    df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
        "\n",
        "    # Create a dictionary to count ships per filename\n",
        "    ship_count = {}\n",
        "\n",
        "    # Iterate through the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        filename = row[0]  # Picture filename\n",
        "        rle = row[1]  # RLE encoded map\n",
        "\n",
        "        # Only process if the filename is a string and is not NaN\n",
        "        if isinstance(filename, str) and filename.strip():\n",
        "            if filename not in ship_count:\n",
        "                ship_count[filename] = 0  # Initialize count for the filename\n",
        "\n",
        "            # If RLE is not empty (and is a string), increment the ship count for this filename\n",
        "            if isinstance(rle, str) and rle.strip():  # If there is an RLE code, it means there is at least one ship\n",
        "                ship_count[filename] += 1\n",
        "\n",
        "    # Count how many pictures have 0, 1, 2, etc. ships\n",
        "    ship_distribution = {}\n",
        "    for count in ship_count.values():\n",
        "        if count not in ship_distribution:\n",
        "            ship_distribution[count] = 0\n",
        "        ship_distribution[count] += 1  # Count the occurrences of each ship count\n",
        "\n",
        "    return ship_count, ship_distribution  # Return both dictionaries\n",
        "\n",
        "def plot_ship_distribution(ship_distribution):\n",
        "    # Prepare data for plotting\n",
        "    counts = list(ship_distribution.keys())\n",
        "    num_pictures = list(ship_distribution.values())\n",
        "\n",
        "    # Create a histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(counts, num_pictures, color='skyblue')\n",
        "    plt.xlabel('Number of Ships in the Picture')\n",
        "    plt.ylabel('Number of Pictures')\n",
        "    plt.title('Distribution of Ships in Pictures')\n",
        "    plt.xticks(counts) #number of ships\n",
        "    plt.grid(axis='y')\n",
        "    plt.show()\n",
        "\n",
        "# Function to find the picture with the maximum number of ships just for a funfact\n",
        "def find_max_ships_picture(ship_count):\n",
        "    max_ships = -1\n",
        "    max_picture = None\n",
        "\n",
        "    for filename, count in ship_count.items():\n",
        "        if count > max_ships:\n",
        "            max_ships = count\n",
        "            max_picture = filename\n",
        "\n",
        "    return max_picture, max_ships\n",
        "\n",
        "# Count ships and plot the distribution\n",
        "ship_count, ship_distribution = count_ships(csv_path)\n",
        "plot_ship_distribution(ship_distribution)\n",
        "\n",
        "max_picture, max_ships = find_max_ships_picture(ship_count)\n",
        "\n",
        "print(f\"The picture with the most ships is '{max_picture}' with {max_ships} ships.\")\n"
      ],
      "metadata": {
        "id": "_4RHtvtGlBe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the dataset for traning"
      ],
      "metadata": {
        "id": "vh3jtQlVx8bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the .csv file, skipping the first row for safety\n",
        "df = pd.read_csv('/content/train_ship_segmentations_v2.csv', skiprows=1, header=None, names=['filename', 'rle_data'])\n",
        "\n",
        "# Convert RLE data to string, replacing NaN with an empty string\n",
        "df['rle_data'] = df['rle_data'].astype(str).replace('nan', '')\n",
        "\n",
        "# Group by filename and combine the RLE data, so that every picture only has one RLE output containing all the information\n",
        "combined_df = df.groupby('filename')['rle_data'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "# Save the combined data to a new CSV file\n",
        "combined_df.to_csv('combined_rle_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "e5OGztTB3gKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###*This* segment creates the output images from the rle data in the .csv file"
      ],
      "metadata": {
        "id": "oScaXcMT4bsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = '/content/combined_rle_data.csv'\n",
        "output_folder = '/content/rle_images'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Function to decode the rle codes for output data visualization\n",
        "def rle_decode(rle, height, width):\n",
        "    # Decodes the RLE encoded string into a binary mask (image) filled column by column.\n",
        "    rle = list(map(int, rle.split()))\n",
        "    img = np.zeros((height, width), dtype=np.uint8)  # Create an empty 2D array\n",
        "\n",
        "    for start, length in zip(rle[::2], rle[1::2]):\n",
        "        # Calculate column and row based on column-major order\n",
        "        col_start = start // height  # Column index\n",
        "        row_start = start % height    # Row index within that column\n",
        "\n",
        "        for i in range(length):\n",
        "            # Fill the pixel in column-major order\n",
        "            img[(row_start + i) % height, col_start] = 255  # Update the corresponding pixel\n",
        "\n",
        "    return img\n",
        "\n",
        "# Creates the output images from the rle data\n",
        "def process_rle_images(csv_path, output_folder):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    with open(csv_path, 'r') as file:\n",
        "        # Skip the first row (header)\n",
        "        next(file)\n",
        "\n",
        "        # Process each line in the CSV\n",
        "        for line in file:\n",
        "            # Strip whitespace and split by comma\n",
        "            parts = line.strip().split(',')\n",
        "            if len(parts) != 2:\n",
        "                print(f\"Skipping invalid line: {line.strip()}\")\n",
        "                continue  # Skip invalid lines\n",
        "\n",
        "            filename, rle = parts\n",
        "            filename = filename.strip()\n",
        "            rle = rle.strip()\n",
        "\n",
        "            # Decode the RLE into a 768x768 image\n",
        "            img_data = rle_decode(rle, height=768, width=768)\n",
        "\n",
        "            # Create an image from the array\n",
        "            img = Image.fromarray(img_data, mode='L')  # 'L' mode for grayscale\n",
        "\n",
        "            img.save(os.path.join(output_folder, filename))\n",
        "\n",
        "# Process the images from RLE\n",
        "process_rle_images(csv_path, output_folder)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2azd1dFjW9BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set path to the .csv file containig the output rle-s\n",
        "csv_path = '/content/train_ship_segmentations_v2.csv'\n",
        "\n",
        "df = pd.read_csv(csv_path, header=None, skiprows=1)\n",
        "\n",
        "# Initialize a dictionary to hold counts\n",
        "ship_count = {}\n",
        "\n",
        "# Iterate through each picture\n",
        "for index, row in df.iterrows():\n",
        "    filename = row[0]  # Picture filename\n",
        "    rle = row[1]  # RLE encoded map\n",
        "\n",
        "    # Only process if the filename is a string and is not NaN\n",
        "    if isinstance(filename, str) and filename.strip():\n",
        "        if filename not in ship_count:\n",
        "            ship_count[filename] = {'count': 0, 'has_rle': False}\n",
        "\n",
        "        # Count occurrences\n",
        "        ship_count[filename]['count'] += 1\n",
        "\n",
        "        # Check if there is an RLE code (indicating a ship is present)\n",
        "        if isinstance(rle, str) and rle.strip():  # If there is an RLE code\n",
        "            ship_count[filename]['has_rle'] = True\n",
        "\n",
        "# Finalize the ship counts based on occurrences and presence of RLE\n",
        "final_ship_count = {filename: (data['count'] if data['has_rle'] else 0) for filename, data in ship_count.items()}\n",
        "\n",
        "dir1 = '/content/rle_images'\n",
        "dir2 = '/content/train_v2'\n",
        "\n",
        "#paring image names to ship counts\n",
        "\n",
        "# List of files in both directories\n",
        "files_dir1 = set(os.listdir(dir1))\n",
        "files_dir2 = set(os.listdir(dir2))\n",
        "\n",
        "# Find the common files between the two directories\n",
        "common_files = files_dir1.intersection(files_dir2)\n",
        "\n",
        "# Create a list to store the image pairs and counts\n",
        "image_pairs = []\n",
        "total_pairs_found = 0  # Initialize a counter for pairs found\n",
        "\n",
        "# Create pairs of images with ship count\n",
        "for file_name in common_files:\n",
        "    count = final_ship_count.get(file_name, 0)  # Get the count, default to 0 if not found\n",
        "    image_pairs.append((file_name, count))\n",
        "    total_pairs_found += 1  # Increment the counter for each pair found\n",
        "\n",
        "# Print the total number of pairs found\n",
        "print(f\"\\nTotal Pairs Found: {total_pairs_found}\")\n"
      ],
      "metadata": {
        "id": "djagz5StY9W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###This segment will seperate the pictures into two different arrays, based on wether they contain ships or not."
      ],
      "metadata": {
        "id": "olRTJWNeO9AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_filenames_by_ship_count(image_pairs):\n",
        "    # Initialize arrays for images with and without ships\n",
        "    images_with_ships = []\n",
        "    images_without_ships = []\n",
        "\n",
        "    # Separate images based on ship count\n",
        "    for filename, count in image_pairs:\n",
        "        if count > 0:\n",
        "            images_with_ships.append((filename, count))  # Append to images with ships\n",
        "        else:\n",
        "            images_without_ships.append((filename, count))  # Append to images without ships\n",
        "\n",
        "    return images_with_ships, images_without_ships\n",
        "\n",
        "# Call the function\n",
        "with_ships, without_ships = separate_filenames_by_ship_count(image_pairs)\n",
        "\n",
        "# Output the results\n",
        "print(\"Images with ships:\", len(with_ships))\n",
        "print(\"Images without ships:\", len(without_ships))\n"
      ],
      "metadata": {
        "id": "pNLrBt8QaC6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will show 5 samples of how the mask looks like after decoding it into 768x768 pictures. The purple color masked over the original picture is the RLE encoded pixels of the mask. If for some reason the picture loading fails the program will give an error message. (Running this code segment multiple times is enabled, it will just show 5 other pictures as samples)\n",
        "\n",
        "Note: The samples shown are only selected from pictures that contain at least one ship"
      ],
      "metadata": {
        "id": "ECacwrwGRHLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories containing the images\n",
        "dir_original = '/content/train_v2'  # Path to the original images\n",
        "dir_rle = '/content/rle_images'       # Path to the RLE images\n",
        "\n",
        "#Because we used different methods this was implemented\n",
        "if isinstance(with_ships, np.ndarray):\n",
        "    # Choose 5 random elements from the first column of the array\n",
        "    selected_images = random.sample(list(with_ships[:, 0]), 5)  # Extract only the first column for filenames\n",
        "else:\n",
        "    # With_ships is a list containing filenames in the first position\n",
        "    selected_images = random.sample([entry[0] for entry in with_ships], 5)\n",
        "\n",
        "# Plot preparation:\n",
        "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "for i, image_name in enumerate(selected_images):\n",
        "    # Load the original and RLE images\n",
        "    original_path = os.path.join(dir_original, f\"{image_name}\")\n",
        "    rle_path = os.path.join(dir_rle, f\"{image_name}\")\n",
        "\n",
        "    original_image = cv2.imread(original_path)\n",
        "    rle_image = cv2.imread(rle_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "\n",
        "    # Check if images are loaded correctly\n",
        "    if original_image is None:\n",
        "        print(f\"Error loading original image: {original_path}\")\n",
        "        continue\n",
        "    if rle_image is None:\n",
        "        print(f\"Error loading RLE image: {rle_path}\")\n",
        "        continue\n",
        "\n",
        "    # Create a binary mask\n",
        "    binary_mask = (rle_image == 255).astype(np.uint8)  # 1 where white pixels, 0 where black pixels\n",
        "\n",
        "    # Create an RGB mask with the desired color (magenta)\n",
        "    color_mask = np.zeros_like(original_image, dtype=np.uint8)\n",
        "    color_mask[binary_mask == 1] = [255, 0, 255]  # Assign magenta color to white regions\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    masked_image = cv2.addWeighted(original_image, 1, color_mask,1, 0)  # Blend the mask with the original image\n",
        "\n",
        "    #Plot the masked image\n",
        "    axes[i].imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))\n",
        "    axes[i].set_title(image_name)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BEWcs0yNC-x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training after hyperparameter optimisation (hyp opt is in another file. The best modell was imported and trained here)"
      ],
      "metadata": {
        "id": "EuSrzL20ycfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boulding Traning, validation and test sets"
      ],
      "metadata": {
        "id": "OMmPJsEaHD0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code segment we wanted to make the dataset less assymetrical, because according to the histogram where we counted the number of ships on every picture, we could see that there are way more pictures without any, than there are with at least 1. There is a parameter in the beginning of the code that can change the amount of pictures with at least 1 ship, and the rest will be filled with randomly selected shipless pictures. (For example if the proportion is 0.7, it means that the main dataset will contain all the pictures with ships and it will fill 70% of the learning dataset, the remaining 30% is pictures without ships)"
      ],
      "metadata": {
        "id": "zKPHpT4uQ5WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proportion = 0.7 #data% with ships\n",
        "val_split = 0.01  # Proportion for validation\n",
        "test_split = 0.0075  # Proportion for test\n",
        "\n",
        "def merge_random_elements(with_ships, without_ships, proportion): #function to create the main traning dataset\n",
        "\n",
        "    x = int(len(with_ships)/proportion*(1-proportion))\n",
        "    # Shuffle the without_ships array\n",
        "    random.shuffle(without_ships)\n",
        "\n",
        "    # Take the first x elements from the shuffled without_ships array\n",
        "    selected_without_ships = without_ships[:x]\n",
        "\n",
        "    # Merge the selected elements with the with_ships array\n",
        "    main_data = with_ships + selected_without_ships\n",
        "    random.shuffle(main_data)\n",
        "\n",
        "    return main_data\n",
        "\n",
        "main_data = merge_random_elements(with_ships, without_ships, proportion) #when teaching the NN, these pictures will be used\n",
        "\n",
        "val_size = int(len(main_data) * val_split)\n",
        "test_size = int(len(main_data) * test_split)\n",
        "\n",
        "val_data = main_data[:val_size]\n",
        "test_data = main_data[val_size : val_size + test_size]\n",
        "main_data = main_data[val_size + test_size:] #is also the traning data (has this name because it was used later and it would be a pain to rename elswhere)\n",
        "\n",
        "# Sizes\n",
        "print(f\"Train size: {len(main_data)}\")\n",
        "print(f\"Validation size: {len(val_data)}\")\n",
        "print(f\"Test size: {len(test_data)}\")\n",
        "print(f\"Whith ships in train: {len([x for x in main_data if x[1] > 0])}\")\n",
        "print(f\"Without ships in train: {len([x for x in main_data if x[1] == 0])}\")\n",
        "\n",
        "#Note that we won't be loading the pictures into arrays because it will take unnecessary memory space and\n",
        "#converting the pictures into arrays does not take significant time when teaching the network (this may not be exactly true, but dou to size limitations in colabe we will do this to be safe)"
      ],
      "metadata": {
        "id": "cO_LubIHByry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the modell"
      ],
      "metadata": {
        "id": "4dvpJsU9HN0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we built the rcnn described in the documentation, with the relevant hyperparameters"
      ],
      "metadata": {
        "id": "vmiZCv4lKIM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Constant parameters (ofc when doing hyperparameterr opt the model may be optimised for them)\n",
        "IMAGE_SIZE = (384, 384)\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 1\n",
        "NUM_CLASSES = 2  # Background and ships\n",
        "\n",
        "# Data Generator to Load Images and Masks\n",
        "def data_generator(main_data, image_dir, mask_dir, batch_size=BATCH_SIZE):\n",
        "    while True:\n",
        "        batch_data = random.sample(main_data, batch_size)\n",
        "        images, masks = [], []\n",
        "\n",
        "        for filename, _ in batch_data:\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            mask_path = os.path.join(mask_dir, filename)\n",
        "\n",
        "            # Load image and mask\n",
        "            image = cv2.imread(img_path)\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Check if images are loaded correctly\n",
        "            if image is None:\n",
        "                print(f\"Error loading image: {img_path}\")\n",
        "                continue\n",
        "            if mask is None:\n",
        "                print(f\"Error loading mask: {mask_path}\")\n",
        "                continue\n",
        "\n",
        "            # Resize for uniformity\n",
        "            image = cv2.resize(image, IMAGE_SIZE)\n",
        "            mask = cv2.resize(mask, IMAGE_SIZE)\n",
        "\n",
        "            # Normalize images and binary masks\n",
        "            image = image.astype(np.float32) / 255.0\n",
        "            mask = (mask > 0).astype(np.float32)  # Binary mask\n",
        "\n",
        "            images.append(image)\n",
        "            masks.append(mask)\n",
        "\n",
        "        # Ensuring that the batch is complete\n",
        "        if len(images) == 0:\n",
        "            continue\n",
        "\n",
        "        yield np.array(images), np.array(masks).reshape(-1, IMAGE_SIZE[0], IMAGE_SIZE[1], 1)\n",
        "\n",
        "# Backbone: ResNet50 for feature extraction\n",
        "def resnet50_backbone(input_shape):\n",
        "    resnet50 = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "    layer_names = [\"conv2_block3_out\", \"conv3_block4_out\", \"conv4_block6_out\"]\n",
        "    outputs = [resnet50.get_layer(name).output for name in layer_names]\n",
        "    return Model(inputs=resnet50.input, outputs=outputs)\n",
        "\n",
        "def mask_head(roi_feature, num_classes=1):\n",
        "    # Initial convolution\n",
        "    x = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(roi_feature)\n",
        "\n",
        "    # Deconvolution (Transpose Convolution) layers for upsampling\n",
        "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "    # Final convolution to produce the mask output\n",
        "    mask_output = Conv2D(num_classes, (1, 1), activation=\"sigmoid\", name='mask_output')(x)\n",
        "    return mask_output\n",
        "\n",
        "\n",
        "\n",
        "# Build the Mask RCNN model (simplified to output only masks)\n",
        "def build_mask_rcnn(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), num_classes=1):  # Binary mask\n",
        "    input_img = Input(shape=input_shape, name='input_image')\n",
        "    backbone = resnet50_backbone(input_shape)\n",
        "    roi_feature = backbone(input_img)\n",
        "    mask_output = mask_head(roi_feature[-1], num_classes)  # Use last feature layer\n",
        "    model = Model(inputs=input_img, outputs=mask_output, name='Mask_RCNN_Simplified')\n",
        "    return model\n",
        "\n",
        "\n",
        "# Instantiate and compile the model\n",
        "model = build_mask_rcnn()\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# visualizing the model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "26C5YMSlpGTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Traning the modell"
      ],
      "metadata": {
        "id": "FjtJnD6XHZrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initilazing the traning and saved the best modell."
      ],
      "metadata": {
        "id": "nGYd1W3oKUbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('mask_rcnn_best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Training\n",
        "image_dir = '/content/train_v2'\n",
        "mask_dir = '/content/rle_images'\n",
        "train_gen = data_generator(main_data, image_dir, mask_dir)\n",
        "\n",
        "# Calculate steps per epoch\n",
        "steps_per_epoch = len(main_data) // BATCH_SIZE\n",
        "if steps_per_epoch == 0:\n",
        "    steps_per_epoch = 1  # Ensure at least one step per epoch\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "FuajhyrRx8PU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing and solution vizualization"
      ],
      "metadata": {
        "id": "lx5j4y0OHh3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the saved model\n",
        "model = tf.keras.models.load_model('mask_rcnn_best_model.keras')\n",
        "\n",
        "# Load and preprocess the input image\n",
        "image_path = 'test_v2/018d23aea.jpg'  # Image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Resize the image to the input shape the model expects\n",
        "image_resized = cv2.resize(image, (384, 384))\n",
        "\n",
        "# Normalize the image like we did during traning\n",
        "image_resized = image_resized.astype(np.float32) / 255.0\n",
        "\n",
        "# Expand dimensions to add a batch axis\n",
        "image_input = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "# Make prediction\n",
        "predictions = model.predict(image_input)\n",
        "\n",
        "# Step 4: Post-process predictions\n",
        "mask = predictions[0]\n",
        "mask = (mask > 0.5).astype(np.uint8)  # Convert to binary\n",
        "\n",
        "#Plot the original image and the predicted mask using plt\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "#original image\n",
        "axes[0].imshow(image_resized)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# predicted mask\n",
        "axes[1].imshow(mask, cmap='gray')\n",
        "axes[1].set_title(\"Predicted Mask\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xk1C2cIlSqSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}